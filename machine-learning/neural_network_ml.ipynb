{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "path_file = os.path.join(current_dir, \"datasets/diabetes.csv\")\n",
    "df = pd.read_csv(path_file, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pregnancies                 False\n",
       "Glucose                     False\n",
       "BloodPressure               False\n",
       "SkinThickness               False\n",
       "Insulin                     False\n",
       "BMI                         False\n",
       "DiabetesPedigreeFunction    False\n",
       "Age                         False\n",
       "Outcome                     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of rows with 0 values for each variable\n",
      "Pregnancies: 111\n",
      "Glucose: 5\n",
      "BloodPressure: 35\n",
      "SkinThickness: 227\n",
      "Insulin: 374\n",
      "BMI: 11\n",
      "DiabetesPedigreeFunction: 0\n",
      "Age: 0\n",
      "Outcome: 500\n"
     ]
    }
   ],
   "source": [
    "print('Numbers of rows with 0 values for each variable')\n",
    "for col in df.columns:\n",
    "    missing_rows = df.loc[df[col] == 0].shape[0]\n",
    "    print(col + ': ' + str(missing_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numbers of rows with 0 values for each variable\n",
      "Pregnancies: 111\n",
      "Glucose: 0\n",
      "BloodPressure: 0\n",
      "SkinThickness: 0\n",
      "Insulin: 0\n",
      "BMI: 0\n",
      "DiabetesPedigreeFunction: 0\n",
      "Age: 0\n",
      "Outcome: 500\n"
     ]
    }
   ],
   "source": [
    "# Padronização dos dados\n",
    "import numpy as np\n",
    "\n",
    "df['Glucose'] = df['Glucose'].replace(0, np.nan)\n",
    "df['BloodPressure'] = df['BloodPressure'].replace(0, np.nan)\n",
    "df['SkinThickness'] = df['SkinThickness'].replace(0, np.nan)\n",
    "df['Insulin'] = df['Insulin'].replace(0, np.nan)\n",
    "df['BMI'] = df['BMI'].replace(0, np.nan)\n",
    "\n",
    "print('Numbers of rows with 0 values for each variable')\n",
    "for col in df.columns:\n",
    "    missing_rows = df.loc[df[col] == 0].shape[0]\n",
    "    print(col + ': ' + str(missing_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Glucose'] = df['Glucose'].fillna(df['Glucose'].mean())\n",
    "df['BloodPressure'] = df['BloodPressure'].fillna(df['BloodPressure'].mean())\n",
    "df['SkinThickness'] = df['SkinThickness'].fillna(df['SkinThickness'].mean())\n",
    "df['Insulin'] = df['Insulin'].fillna(df['Insulin'].mean())\n",
    "df['BMI'] = df['BMI'].fillna(df['BMI'].mean())\n",
    "\n",
    "# print('Numbers of rows with 0 values for each variable')\n",
    "# for col in df.columns:\n",
    "#     missing_rows = df.loc[df[col] == 0].shape[0]\n",
    "#     print(col + ': ' + str(missing_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_scaled = preprocessing.scale(df)\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=df.columns)\n",
    "\n",
    "# print('Numbers of rows with 0 values for each variable')\n",
    "# for col in df_scaled.columns:\n",
    "#     missing_rows = df_scaled.loc[df_scaled[col] == 0].shape[0]\n",
    "#     print(col + ': ' + str(missing_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.91</td>\n",
       "      <td>2.54</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.95</td>\n",
       "      <td>8.13</td>\n",
       "      <td>5.04</td>\n",
       "      <td>5.88</td>\n",
       "      <td>4.06</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.14</td>\n",
       "      <td>2.55</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.52</td>\n",
       "      <td>1.67</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.19</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "mean         0.00     0.00            0.0           0.00     0.00  0.00   \n",
       "std          1.00     1.00            1.0           1.00     1.00  1.00   \n",
       "max          3.91     2.54            4.1           7.95     8.13  5.04   \n",
       "min          1.14     2.55            4.0           2.52     1.67  2.08   \n",
       "\n",
       "      DiabetesPedigreeFunction   Age  Outcome  \n",
       "mean                      0.00  0.00     0.35  \n",
       "std                       1.00  1.00     0.48  \n",
       "max                       5.88  4.06     1.00  \n",
       "min                       1.19  1.04     0.00  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled['Outcome'] = df['Outcome']\n",
    "df = df_scaled\n",
    "df.describe().loc[['mean', 'std', 'max', 'min'],].round(2).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Numbers of rows with 0 values for each variable')\n",
    "# for col in df.columns:\n",
    "#     missing_rows = df.loc[df[col] == 0].shape[0]\n",
    "#     print(col + ': ' + str(missing_rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'Outcome']\n",
    "y = df.loc[:, 'Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "# X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/caio/anaconda3/envs/ds/lib/python3.9/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Input(shape=(8,)))\n",
    "model.add(Dense(32, activation='relu', input_dim=8))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6235 - loss: 0.6434 - val_accuracy: 0.6667 - val_loss: 0.6143\n",
      "Epoch 2/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6813 - loss: 0.6015 - val_accuracy: 0.6992 - val_loss: 0.5870\n",
      "Epoch 3/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6877 - loss: 0.5722 - val_accuracy: 0.6667 - val_loss: 0.5669\n",
      "Epoch 4/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7200 - loss: 0.5452 - val_accuracy: 0.7073 - val_loss: 0.5522\n",
      "Epoch 5/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7547 - loss: 0.5066 - val_accuracy: 0.7236 - val_loss: 0.5414\n",
      "Epoch 6/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7825 - loss: 0.4722 - val_accuracy: 0.7317 - val_loss: 0.5322\n",
      "Epoch 7/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7677 - loss: 0.4830 - val_accuracy: 0.7317 - val_loss: 0.5275\n",
      "Epoch 8/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7783 - loss: 0.4846 - val_accuracy: 0.7317 - val_loss: 0.5235\n",
      "Epoch 9/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7727 - loss: 0.4560 - val_accuracy: 0.7236 - val_loss: 0.5225\n",
      "Epoch 10/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7679 - loss: 0.4686 - val_accuracy: 0.7236 - val_loss: 0.5214\n",
      "Epoch 11/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7813 - loss: 0.4553 - val_accuracy: 0.7236 - val_loss: 0.5218\n",
      "Epoch 12/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7928 - loss: 0.4268 - val_accuracy: 0.7154 - val_loss: 0.5222\n",
      "Epoch 13/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7927 - loss: 0.4419 - val_accuracy: 0.7154 - val_loss: 0.5226\n",
      "Epoch 14/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7850 - loss: 0.4490 - val_accuracy: 0.7154 - val_loss: 0.5231\n",
      "Epoch 15/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8057 - loss: 0.4169 - val_accuracy: 0.7154 - val_loss: 0.5240\n",
      "Epoch 16/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7894 - loss: 0.4459 - val_accuracy: 0.6992 - val_loss: 0.5235\n",
      "Epoch 17/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7673 - loss: 0.4684 - val_accuracy: 0.6992 - val_loss: 0.5224\n",
      "Epoch 18/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8036 - loss: 0.4269 - val_accuracy: 0.7154 - val_loss: 0.5235\n",
      "Epoch 19/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8059 - loss: 0.4212 - val_accuracy: 0.6911 - val_loss: 0.5239\n",
      "Epoch 20/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7967 - loss: 0.4145 - val_accuracy: 0.6829 - val_loss: 0.5267\n",
      "Epoch 21/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7751 - loss: 0.4439 - val_accuracy: 0.6911 - val_loss: 0.5251\n",
      "Epoch 22/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8070 - loss: 0.4102 - val_accuracy: 0.7073 - val_loss: 0.5274\n",
      "Epoch 23/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8237 - loss: 0.3760 - val_accuracy: 0.7236 - val_loss: 0.5281\n",
      "Epoch 24/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8210 - loss: 0.4106 - val_accuracy: 0.6992 - val_loss: 0.5294\n",
      "Epoch 25/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8114 - loss: 0.3868 - val_accuracy: 0.7236 - val_loss: 0.5227\n",
      "Epoch 26/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8142 - loss: 0.3945 - val_accuracy: 0.7154 - val_loss: 0.5236\n",
      "Epoch 27/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8008 - loss: 0.4218 - val_accuracy: 0.7154 - val_loss: 0.5240\n",
      "Epoch 28/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7972 - loss: 0.4109 - val_accuracy: 0.7154 - val_loss: 0.5247\n",
      "Epoch 29/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8152 - loss: 0.3909 - val_accuracy: 0.7236 - val_loss: 0.5250\n",
      "Epoch 30/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8141 - loss: 0.3976 - val_accuracy: 0.7236 - val_loss: 0.5246\n",
      "Epoch 31/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8037 - loss: 0.4059 - val_accuracy: 0.7154 - val_loss: 0.5296\n",
      "Epoch 32/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8366 - loss: 0.3632 - val_accuracy: 0.7236 - val_loss: 0.5312\n",
      "Epoch 33/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8257 - loss: 0.3788 - val_accuracy: 0.7154 - val_loss: 0.5320\n",
      "Epoch 34/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8231 - loss: 0.3825 - val_accuracy: 0.7154 - val_loss: 0.5305\n",
      "Epoch 35/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8218 - loss: 0.3775 - val_accuracy: 0.7236 - val_loss: 0.5315\n",
      "Epoch 36/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8353 - loss: 0.3598 - val_accuracy: 0.7317 - val_loss: 0.5293\n",
      "Epoch 37/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8345 - loss: 0.3710 - val_accuracy: 0.7236 - val_loss: 0.5289\n",
      "Epoch 38/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8093 - loss: 0.3943 - val_accuracy: 0.7073 - val_loss: 0.5302\n",
      "Epoch 39/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8422 - loss: 0.3587 - val_accuracy: 0.7154 - val_loss: 0.5278\n",
      "Epoch 40/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8306 - loss: 0.3833 - val_accuracy: 0.7154 - val_loss: 0.5281\n",
      "Epoch 41/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8258 - loss: 0.3669 - val_accuracy: 0.7154 - val_loss: 0.5279\n",
      "Epoch 42/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8123 - loss: 0.3829 - val_accuracy: 0.7154 - val_loss: 0.5270\n",
      "Epoch 43/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8133 - loss: 0.4129 - val_accuracy: 0.7154 - val_loss: 0.5283\n",
      "Epoch 44/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8178 - loss: 0.3787 - val_accuracy: 0.7154 - val_loss: 0.5273\n",
      "Epoch 45/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8465 - loss: 0.3452 - val_accuracy: 0.7154 - val_loss: 0.5291\n",
      "Epoch 46/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8296 - loss: 0.3645 - val_accuracy: 0.7154 - val_loss: 0.5326\n",
      "Epoch 47/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8342 - loss: 0.3555 - val_accuracy: 0.6911 - val_loss: 0.5334\n",
      "Epoch 48/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8414 - loss: 0.3304 - val_accuracy: 0.7154 - val_loss: 0.5320\n",
      "Epoch 49/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8262 - loss: 0.3581 - val_accuracy: 0.7154 - val_loss: 0.5304\n",
      "Epoch 50/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8174 - loss: 0.3713 - val_accuracy: 0.7154 - val_loss: 0.5265\n",
      "Epoch 51/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8526 - loss: 0.3420 - val_accuracy: 0.7154 - val_loss: 0.5288\n",
      "Epoch 52/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8717 - loss: 0.3300 - val_accuracy: 0.7236 - val_loss: 0.5288\n",
      "Epoch 53/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8288 - loss: 0.3422 - val_accuracy: 0.7154 - val_loss: 0.5296\n",
      "Epoch 54/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8376 - loss: 0.3437 - val_accuracy: 0.7073 - val_loss: 0.5310\n",
      "Epoch 55/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8477 - loss: 0.3317 - val_accuracy: 0.7073 - val_loss: 0.5345\n",
      "Epoch 56/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8457 - loss: 0.3414 - val_accuracy: 0.7236 - val_loss: 0.5321\n",
      "Epoch 57/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8111 - loss: 0.3546 - val_accuracy: 0.7073 - val_loss: 0.5338\n",
      "Epoch 58/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8326 - loss: 0.3420 - val_accuracy: 0.7073 - val_loss: 0.5341\n",
      "Epoch 59/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8433 - loss: 0.3276 - val_accuracy: 0.7317 - val_loss: 0.5336\n",
      "Epoch 60/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8635 - loss: 0.3087 - val_accuracy: 0.7317 - val_loss: 0.5345\n",
      "Epoch 61/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8266 - loss: 0.3511 - val_accuracy: 0.7073 - val_loss: 0.5362\n",
      "Epoch 62/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8258 - loss: 0.3615 - val_accuracy: 0.7154 - val_loss: 0.5332\n",
      "Epoch 63/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8481 - loss: 0.3357 - val_accuracy: 0.7236 - val_loss: 0.5361\n",
      "Epoch 64/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8356 - loss: 0.3496 - val_accuracy: 0.7154 - val_loss: 0.5368\n",
      "Epoch 65/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8510 - loss: 0.3366 - val_accuracy: 0.7236 - val_loss: 0.5367\n",
      "Epoch 66/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8532 - loss: 0.3337 - val_accuracy: 0.7154 - val_loss: 0.5377\n",
      "Epoch 67/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8180 - loss: 0.3625 - val_accuracy: 0.7154 - val_loss: 0.5426\n",
      "Epoch 68/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8764 - loss: 0.3073 - val_accuracy: 0.7236 - val_loss: 0.5429\n",
      "Epoch 69/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8695 - loss: 0.3169 - val_accuracy: 0.7073 - val_loss: 0.5390\n",
      "Epoch 70/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8494 - loss: 0.3354 - val_accuracy: 0.7073 - val_loss: 0.5422\n",
      "Epoch 71/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8729 - loss: 0.3051 - val_accuracy: 0.7154 - val_loss: 0.5439\n",
      "Epoch 72/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8509 - loss: 0.3265 - val_accuracy: 0.7236 - val_loss: 0.5401\n",
      "Epoch 73/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8592 - loss: 0.3271 - val_accuracy: 0.7154 - val_loss: 0.5461\n",
      "Epoch 74/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8483 - loss: 0.3320 - val_accuracy: 0.7073 - val_loss: 0.5516\n",
      "Epoch 75/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8659 - loss: 0.3090 - val_accuracy: 0.7154 - val_loss: 0.5492\n",
      "Epoch 76/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8479 - loss: 0.3356 - val_accuracy: 0.7073 - val_loss: 0.5497\n",
      "Epoch 77/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8354 - loss: 0.3342 - val_accuracy: 0.7073 - val_loss: 0.5512\n",
      "Epoch 78/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8430 - loss: 0.3437 - val_accuracy: 0.7073 - val_loss: 0.5479\n",
      "Epoch 79/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8943 - loss: 0.2933 - val_accuracy: 0.7236 - val_loss: 0.5525\n",
      "Epoch 80/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8629 - loss: 0.3069 - val_accuracy: 0.7236 - val_loss: 0.5537\n",
      "Epoch 81/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8726 - loss: 0.2976 - val_accuracy: 0.7073 - val_loss: 0.5591\n",
      "Epoch 82/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8736 - loss: 0.2918 - val_accuracy: 0.7154 - val_loss: 0.5600\n",
      "Epoch 83/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8625 - loss: 0.2972 - val_accuracy: 0.7154 - val_loss: 0.5594\n",
      "Epoch 84/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8925 - loss: 0.2787 - val_accuracy: 0.7154 - val_loss: 0.5634\n",
      "Epoch 85/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8705 - loss: 0.3100 - val_accuracy: 0.7073 - val_loss: 0.5660\n",
      "Epoch 86/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8544 - loss: 0.3188 - val_accuracy: 0.7236 - val_loss: 0.5643\n",
      "Epoch 87/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8658 - loss: 0.2839 - val_accuracy: 0.7154 - val_loss: 0.5692\n",
      "Epoch 88/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8568 - loss: 0.3090 - val_accuracy: 0.7154 - val_loss: 0.5660\n",
      "Epoch 89/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8690 - loss: 0.3065 - val_accuracy: 0.6992 - val_loss: 0.5724\n",
      "Epoch 90/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8216 - loss: 0.3601 - val_accuracy: 0.7154 - val_loss: 0.5696\n",
      "Epoch 91/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8737 - loss: 0.2931 - val_accuracy: 0.7154 - val_loss: 0.5704\n",
      "Epoch 92/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8504 - loss: 0.2997 - val_accuracy: 0.7154 - val_loss: 0.5753\n",
      "Epoch 93/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8654 - loss: 0.2995 - val_accuracy: 0.7154 - val_loss: 0.5777\n",
      "Epoch 94/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8721 - loss: 0.2837 - val_accuracy: 0.7154 - val_loss: 0.5748\n",
      "Epoch 95/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8737 - loss: 0.2956 - val_accuracy: 0.7154 - val_loss: 0.5757\n",
      "Epoch 96/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8653 - loss: 0.3021 - val_accuracy: 0.7073 - val_loss: 0.5853\n",
      "Epoch 97/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8741 - loss: 0.2956 - val_accuracy: 0.7154 - val_loss: 0.5790\n",
      "Epoch 98/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8665 - loss: 0.2816 - val_accuracy: 0.7073 - val_loss: 0.5898\n",
      "Epoch 99/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8653 - loss: 0.2797 - val_accuracy: 0.7073 - val_loss: 0.5909\n",
      "Epoch 100/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8899 - loss: 0.2650 - val_accuracy: 0.7073 - val_loss: 0.5883\n",
      "Epoch 101/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8749 - loss: 0.2835 - val_accuracy: 0.7073 - val_loss: 0.5944\n",
      "Epoch 102/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8689 - loss: 0.2868 - val_accuracy: 0.7073 - val_loss: 0.5935\n",
      "Epoch 103/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8763 - loss: 0.2938 - val_accuracy: 0.7073 - val_loss: 0.5975\n",
      "Epoch 104/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8744 - loss: 0.2642 - val_accuracy: 0.7073 - val_loss: 0.6033\n",
      "Epoch 105/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8679 - loss: 0.2960 - val_accuracy: 0.7073 - val_loss: 0.6033\n",
      "Epoch 106/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8739 - loss: 0.2926 - val_accuracy: 0.7073 - val_loss: 0.6062\n",
      "Epoch 107/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8565 - loss: 0.2933 - val_accuracy: 0.7073 - val_loss: 0.6021\n",
      "Epoch 108/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8828 - loss: 0.2680 - val_accuracy: 0.6992 - val_loss: 0.6151\n",
      "Epoch 109/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8775 - loss: 0.2917 - val_accuracy: 0.7073 - val_loss: 0.6086\n",
      "Epoch 110/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9009 - loss: 0.2693 - val_accuracy: 0.7073 - val_loss: 0.6065\n",
      "Epoch 111/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8707 - loss: 0.2899 - val_accuracy: 0.6992 - val_loss: 0.6083\n",
      "Epoch 112/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8504 - loss: 0.3054 - val_accuracy: 0.7073 - val_loss: 0.6078\n",
      "Epoch 113/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8929 - loss: 0.2595 - val_accuracy: 0.7073 - val_loss: 0.6153\n",
      "Epoch 114/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8805 - loss: 0.2631 - val_accuracy: 0.6992 - val_loss: 0.6257\n",
      "Epoch 115/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8913 - loss: 0.2457 - val_accuracy: 0.6911 - val_loss: 0.6193\n",
      "Epoch 116/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9029 - loss: 0.2552 - val_accuracy: 0.6911 - val_loss: 0.6219\n",
      "Epoch 117/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8819 - loss: 0.2604 - val_accuracy: 0.6911 - val_loss: 0.6228\n",
      "Epoch 118/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9056 - loss: 0.2461 - val_accuracy: 0.6911 - val_loss: 0.6195\n",
      "Epoch 119/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8723 - loss: 0.2695 - val_accuracy: 0.6911 - val_loss: 0.6309\n",
      "Epoch 120/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9094 - loss: 0.2478 - val_accuracy: 0.6911 - val_loss: 0.6342\n",
      "Epoch 121/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8957 - loss: 0.2619 - val_accuracy: 0.6911 - val_loss: 0.6280\n",
      "Epoch 122/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8843 - loss: 0.2667 - val_accuracy: 0.6911 - val_loss: 0.6249\n",
      "Epoch 123/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8913 - loss: 0.2462 - val_accuracy: 0.6911 - val_loss: 0.6383\n",
      "Epoch 124/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8862 - loss: 0.2708 - val_accuracy: 0.6911 - val_loss: 0.6368\n",
      "Epoch 125/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8691 - loss: 0.2872 - val_accuracy: 0.6911 - val_loss: 0.6313\n",
      "Epoch 126/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8956 - loss: 0.2422 - val_accuracy: 0.6992 - val_loss: 0.6410\n",
      "Epoch 127/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8833 - loss: 0.2597 - val_accuracy: 0.6911 - val_loss: 0.6392\n",
      "Epoch 128/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8915 - loss: 0.2595 - val_accuracy: 0.6911 - val_loss: 0.6344\n",
      "Epoch 129/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8994 - loss: 0.2392 - val_accuracy: 0.6911 - val_loss: 0.6486\n",
      "Epoch 130/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8994 - loss: 0.2372 - val_accuracy: 0.6911 - val_loss: 0.6463\n",
      "Epoch 131/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9062 - loss: 0.2418 - val_accuracy: 0.6911 - val_loss: 0.6390\n",
      "Epoch 132/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8979 - loss: 0.2545 - val_accuracy: 0.6911 - val_loss: 0.6460\n",
      "Epoch 133/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9177 - loss: 0.2272 - val_accuracy: 0.6911 - val_loss: 0.6489\n",
      "Epoch 134/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9123 - loss: 0.2357 - val_accuracy: 0.6911 - val_loss: 0.6574\n",
      "Epoch 135/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8876 - loss: 0.2574 - val_accuracy: 0.6911 - val_loss: 0.6615\n",
      "Epoch 136/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8850 - loss: 0.2596 - val_accuracy: 0.6911 - val_loss: 0.6590\n",
      "Epoch 137/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9075 - loss: 0.2362 - val_accuracy: 0.6911 - val_loss: 0.6660\n",
      "Epoch 138/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9075 - loss: 0.2318 - val_accuracy: 0.6911 - val_loss: 0.6682\n",
      "Epoch 139/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9208 - loss: 0.2359 - val_accuracy: 0.6911 - val_loss: 0.6715\n",
      "Epoch 140/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8967 - loss: 0.2407 - val_accuracy: 0.6992 - val_loss: 0.6667\n",
      "Epoch 141/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9075 - loss: 0.2277 - val_accuracy: 0.6911 - val_loss: 0.6721\n",
      "Epoch 142/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8945 - loss: 0.2486 - val_accuracy: 0.6911 - val_loss: 0.6741\n",
      "Epoch 143/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9117 - loss: 0.2345 - val_accuracy: 0.6911 - val_loss: 0.6731\n",
      "Epoch 144/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9266 - loss: 0.2215 - val_accuracy: 0.6829 - val_loss: 0.6843\n",
      "Epoch 145/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9125 - loss: 0.2202 - val_accuracy: 0.6992 - val_loss: 0.6805\n",
      "Epoch 146/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9176 - loss: 0.2275 - val_accuracy: 0.6992 - val_loss: 0.6831\n",
      "Epoch 147/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9125 - loss: 0.2344 - val_accuracy: 0.6992 - val_loss: 0.6829\n",
      "Epoch 148/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9266 - loss: 0.2122 - val_accuracy: 0.6992 - val_loss: 0.6920\n",
      "Epoch 149/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9032 - loss: 0.2285 - val_accuracy: 0.6911 - val_loss: 0.6919\n",
      "Epoch 150/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2276 - val_accuracy: 0.6911 - val_loss: 0.7005\n",
      "Epoch 151/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9177 - loss: 0.2242 - val_accuracy: 0.6829 - val_loss: 0.6980\n",
      "Epoch 152/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9102 - loss: 0.2258 - val_accuracy: 0.6829 - val_loss: 0.6947\n",
      "Epoch 153/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8802 - loss: 0.2648 - val_accuracy: 0.6992 - val_loss: 0.6988\n",
      "Epoch 154/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9264 - loss: 0.2011 - val_accuracy: 0.6911 - val_loss: 0.6973\n",
      "Epoch 155/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8990 - loss: 0.2305 - val_accuracy: 0.6829 - val_loss: 0.7099\n",
      "Epoch 156/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9047 - loss: 0.2308 - val_accuracy: 0.6911 - val_loss: 0.6988\n",
      "Epoch 157/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9063 - loss: 0.2426 - val_accuracy: 0.6911 - val_loss: 0.7095\n",
      "Epoch 158/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9028 - loss: 0.2264 - val_accuracy: 0.6911 - val_loss: 0.7084\n",
      "Epoch 159/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9240 - loss: 0.2041 - val_accuracy: 0.6911 - val_loss: 0.7154\n",
      "Epoch 160/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9117 - loss: 0.2373 - val_accuracy: 0.6829 - val_loss: 0.7139\n",
      "Epoch 161/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9153 - loss: 0.2116 - val_accuracy: 0.6911 - val_loss: 0.7124\n",
      "Epoch 162/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9216 - loss: 0.2064 - val_accuracy: 0.6992 - val_loss: 0.7089\n",
      "Epoch 163/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9304 - loss: 0.2050 - val_accuracy: 0.6992 - val_loss: 0.7212\n",
      "Epoch 164/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9291 - loss: 0.1946 - val_accuracy: 0.6992 - val_loss: 0.7340\n",
      "Epoch 165/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9230 - loss: 0.1960 - val_accuracy: 0.6911 - val_loss: 0.7312\n",
      "Epoch 166/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9176 - loss: 0.2180 - val_accuracy: 0.6911 - val_loss: 0.7360\n",
      "Epoch 167/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9201 - loss: 0.2107 - val_accuracy: 0.6911 - val_loss: 0.7310\n",
      "Epoch 168/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9155 - loss: 0.2215 - val_accuracy: 0.6992 - val_loss: 0.7305\n",
      "Epoch 169/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9253 - loss: 0.2075 - val_accuracy: 0.6829 - val_loss: 0.7437\n",
      "Epoch 170/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9077 - loss: 0.2219 - val_accuracy: 0.6992 - val_loss: 0.7374\n",
      "Epoch 171/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9026 - loss: 0.2152 - val_accuracy: 0.6911 - val_loss: 0.7470\n",
      "Epoch 172/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9217 - loss: 0.1981 - val_accuracy: 0.6911 - val_loss: 0.7561\n",
      "Epoch 173/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9115 - loss: 0.2157 - val_accuracy: 0.6829 - val_loss: 0.7613\n",
      "Epoch 174/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9323 - loss: 0.1970 - val_accuracy: 0.6911 - val_loss: 0.7593\n",
      "Epoch 175/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9190 - loss: 0.1994 - val_accuracy: 0.6911 - val_loss: 0.7599\n",
      "Epoch 176/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9330 - loss: 0.1940 - val_accuracy: 0.6992 - val_loss: 0.7644\n",
      "Epoch 177/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9088 - loss: 0.2183 - val_accuracy: 0.6911 - val_loss: 0.7661\n",
      "Epoch 178/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9272 - loss: 0.1916 - val_accuracy: 0.6992 - val_loss: 0.7636\n",
      "Epoch 179/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9258 - loss: 0.2031 - val_accuracy: 0.6911 - val_loss: 0.7717\n",
      "Epoch 180/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9161 - loss: 0.2033 - val_accuracy: 0.6992 - val_loss: 0.7696\n",
      "Epoch 181/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9130 - loss: 0.2164 - val_accuracy: 0.7073 - val_loss: 0.7749\n",
      "Epoch 182/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9082 - loss: 0.2057 - val_accuracy: 0.6992 - val_loss: 0.7722\n",
      "Epoch 183/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9226 - loss: 0.1893 - val_accuracy: 0.6992 - val_loss: 0.7841\n",
      "Epoch 184/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9388 - loss: 0.1746 - val_accuracy: 0.6992 - val_loss: 0.7863\n",
      "Epoch 185/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9311 - loss: 0.2002 - val_accuracy: 0.6911 - val_loss: 0.7817\n",
      "Epoch 186/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8999 - loss: 0.2101 - val_accuracy: 0.6911 - val_loss: 0.7873\n",
      "Epoch 187/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9398 - loss: 0.1737 - val_accuracy: 0.6992 - val_loss: 0.7987\n",
      "Epoch 188/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9341 - loss: 0.1728 - val_accuracy: 0.6992 - val_loss: 0.7918\n",
      "Epoch 189/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9300 - loss: 0.1762 - val_accuracy: 0.6911 - val_loss: 0.7944\n",
      "Epoch 190/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9329 - loss: 0.1825 - val_accuracy: 0.6829 - val_loss: 0.8036\n",
      "Epoch 191/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9283 - loss: 0.1946 - val_accuracy: 0.6911 - val_loss: 0.7875\n",
      "Epoch 192/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9169 - loss: 0.1995 - val_accuracy: 0.6829 - val_loss: 0.7933\n",
      "Epoch 193/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9332 - loss: 0.1776 - val_accuracy: 0.6911 - val_loss: 0.7951\n",
      "Epoch 194/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9397 - loss: 0.1768 - val_accuracy: 0.6992 - val_loss: 0.8017\n",
      "Epoch 195/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9305 - loss: 0.1812 - val_accuracy: 0.6829 - val_loss: 0.8052\n",
      "Epoch 196/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9322 - loss: 0.1877 - val_accuracy: 0.6829 - val_loss: 0.8103\n",
      "Epoch 197/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9287 - loss: 0.1805 - val_accuracy: 0.6829 - val_loss: 0.8129\n",
      "Epoch 198/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9358 - loss: 0.1806 - val_accuracy: 0.6911 - val_loss: 0.8120\n",
      "Epoch 199/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9305 - loss: 0.1948 - val_accuracy: 0.6829 - val_loss: 0.8128\n",
      "Epoch 200/200\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9339 - loss: 0.1742 - val_accuracy: 0.6992 - val_loss: 0.8175\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=200, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9238 - loss: 0.1842 \n",
      "Training Accuracy: 93.08%\n",
      "\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7474 - loss: 0.7778\n",
      "Validation Accuracy: 69.92%\n",
      "\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7572 - loss: 0.5663 \n",
      "Testing Accuracy: 75.97%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_train, y_train)\n",
    "print('Training Accuracy: %.2f%%\\n' % (scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(X_val, y_val)\n",
    "print('Validation Accuracy: %.2f%%\\n' % (scores[1]*100))\n",
    "\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print('Testing Accuracy: %.2f%%\\n' % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d945fe79160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/5\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7d945fe79160> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'True Positive Rate')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "FPR, TPR, _ = roc_curve(y_test, y_test_pred)\n",
    "plt.plot(FPR, TPR)\n",
    "plt.plot([0, 1], [0, 1], '--', color='black')\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
